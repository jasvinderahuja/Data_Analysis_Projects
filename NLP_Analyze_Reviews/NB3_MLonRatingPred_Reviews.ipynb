{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d373c933-3dd1-41cd-82dc-49fba72859e9",
   "metadata": {},
   "source": [
    "# NB3 Rating Predictions\n",
    "- This is work in progress, need to play more with data.\n",
    "- But it conveys the gist.\n",
    "- Need to work on describing interpretability and further optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaedad14-a395-4e37-8820-572e40d56680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b771012b-2db8-458b-a3f3-153b056cbc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23472, 18)\n",
      "(23472, 18)\n",
      "(23472, 18)\n"
     ]
    }
   ],
   "source": [
    "reviews_features = pd.read_csv(\"reviews_features.csv\")\n",
    "print(reviews_features.shape)\n",
    "reviews_features.head()\n",
    "# Remove rows with missing values in the target variable 'Recommend Flag'\n",
    "reviews_features = reviews_features.dropna(subset=['Recommend Flag'])\n",
    "print(reviews_features.shape)\n",
    "reviews_features = reviews_features.dropna(subset=['Rating'])\n",
    "print(reviews_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c091eb7a-9bef-447a-aec2-e76d64f1d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "\n",
    "# Select columns for each transformation type\n",
    "predicts = ['Rating', 'Recommend Flag']\n",
    "labels = ['Product ID']\n",
    "categorical_cols = ['Category', 'Subcategory1', 'SubCategory2', 'Location', 'Channel', 'age_bins', ]\n",
    "numeric_cols = ['review_len', 'noun_strength', 'polarity', 'subjectivity_score', 'compound_VADER_score', 'unique_word_fraction'] \n",
    "binary_cols = ['is_gibberish']\n",
    "\n",
    "# One-Hot Encoding for categorical features\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first') \n",
    "categorical_encoded = ohe.fit_transform(reviews_features[categorical_cols])\n",
    "\n",
    "# Create DataFrame with OHE features\n",
    "ohe_df = pd.DataFrame(categorical_encoded, columns=ohe.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "numeric_scaled = scaler.fit_transform(reviews_features[numeric_cols])\n",
    "\n",
    "# Create DataFrame with scaled numerical features\n",
    "numeric_df = pd.DataFrame(numeric_scaled, columns=numeric_cols)\n",
    "\n",
    "# Combine all features into a final DataFrame\n",
    "reviewsFE_final_df = pd.concat([ohe_df, numeric_df, reviews_features[binary_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "reviewsFE_final_df = pd.concat([reviewsFE_final_df, reviews_features[['Product ID','Rating', 'Recommend Flag']]], axis=1)\n",
    "\n",
    "to_drop = ['Product ID','Rating', 'Recommend Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414560ef-472e-4b17-abbb-8176415b8907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_x000d_</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>big</th>\n",
       "      <th>bit</th>\n",
       "      <th>buy</th>\n",
       "      <th>color</th>\n",
       "      <th>comfortable</th>\n",
       "      <th>cute</th>\n",
       "      <th>dress</th>\n",
       "      <th>fabric</th>\n",
       "      <th>...</th>\n",
       "      <th>skirt</th>\n",
       "      <th>small</th>\n",
       "      <th>soft</th>\n",
       "      <th>sweater</th>\n",
       "      <th>think</th>\n",
       "      <th>try</th>\n",
       "      <th>waist</th>\n",
       "      <th>want</th>\n",
       "      <th>wear</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.228564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.610343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.398506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.294867</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207795</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23467</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23469</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.397934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405721</td>\n",
       "      <td>0.470379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244071</td>\n",
       "      <td>0.243254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23471</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420662</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23472 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _x000d_  beautiful       big  bit       buy     color  comfortable  \\\n",
       "0          0.0        0.0  0.000000  0.0  0.000000  0.000000     1.000000   \n",
       "1          0.0        0.0  0.000000  0.0  0.221448  0.000000     0.000000   \n",
       "2          0.0        0.0  0.000000  0.0  0.000000  0.000000     0.228564   \n",
       "3          0.0        0.0  0.000000  0.0  0.398506  0.000000     0.000000   \n",
       "4          0.0        0.0  0.000000  0.0  0.000000  0.000000     0.000000   \n",
       "...        ...        ...       ...  ...       ...       ...          ...   \n",
       "23467      0.0        0.0  0.000000  0.0  0.000000  0.308829     0.000000   \n",
       "23468      0.0        0.0  0.000000  0.0  0.000000  0.000000     0.000000   \n",
       "23469      0.0        0.0  0.000000  0.0  0.000000  0.000000     0.000000   \n",
       "23470      0.0        0.0  0.240827  0.0  0.206671  0.000000     0.000000   \n",
       "23471      0.0        0.0  0.000000  0.0  0.000000  0.000000     0.000000   \n",
       "\n",
       "           cute     dress    fabric  ...  skirt     small      soft  sweater  \\\n",
       "0      0.000000  0.000000  0.000000  ...    0.0  0.000000  0.000000      0.0   \n",
       "1      0.000000  0.168004  0.000000  ...    0.0  0.000000  0.000000      0.0   \n",
       "2      0.000000  0.168755  0.000000  ...    0.0  0.610343  0.000000      0.0   \n",
       "3      0.000000  0.000000  0.000000  ...    0.0  0.000000  0.000000      0.0   \n",
       "4      0.000000  0.000000  0.000000  ...    0.0  0.000000  0.000000      0.0   \n",
       "...         ...       ...       ...  ...    ...       ...       ...      ...   \n",
       "23467  0.000000  0.592446  0.000000  ...    0.0  0.000000  0.000000      0.0   \n",
       "23468  0.000000  0.000000  0.000000  ...    0.0  0.000000  0.378256      0.0   \n",
       "23469  0.397934  0.000000  0.372533  ...    0.0  0.000000  0.000000      0.0   \n",
       "23470  0.405721  0.470379  0.000000  ...    0.0  0.000000  0.000000      0.0   \n",
       "23471  0.000000  0.431309  0.000000  ...    0.0  0.000000  0.000000      0.0   \n",
       "\n",
       "       think       try     waist      want      wear      work  \n",
       "0        0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1        0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2        0.0  0.000000  0.000000  0.000000  0.000000  0.239856  \n",
       "3        0.0  0.000000  0.000000  0.000000  0.294867  0.000000  \n",
       "4        0.0  0.000000  0.000000  0.000000  0.207795  0.000000  \n",
       "...      ...       ...       ...       ...       ...       ...  \n",
       "23467    0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "23468    0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "23469    0.0  0.433679  0.000000  0.000000  0.000000  0.437153  \n",
       "23470    0.0  0.000000  0.244071  0.243254  0.000000  0.000000  \n",
       "23471    0.0  0.000000  0.000000  0.000000  0.420662  0.000000  \n",
       "\n",
       "[23472 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=50, stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(reviews_features['lemmatized'])\n",
    "words_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ca82d6-5e4f-40a8-a9e1-e24ff1bf162b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Category_General Petite', 'Category_Initmates', 'Subcategory1_Dresses',\n",
      "       'Subcategory1_Intimate', 'Subcategory1_Jackets', 'Subcategory1_Tops',\n",
      "       'Subcategory1_Trend', 'SubCategory2_Casual bottoms',\n",
      "       'SubCategory2_Chemises', 'SubCategory2_Dresses',\n",
      "       'SubCategory2_Fine gauge', 'SubCategory2_Intimates',\n",
      "       'SubCategory2_Jackets', 'SubCategory2_Jeans', 'SubCategory2_Knits',\n",
      "       'SubCategory2_Layering', 'SubCategory2_Legwear', 'SubCategory2_Lounge',\n",
      "       'SubCategory2_Outerwear', 'SubCategory2_Pants', 'SubCategory2_Shorts',\n",
      "       'SubCategory2_Skirts', 'SubCategory2_Sleep', 'SubCategory2_Sweaters',\n",
      "       'SubCategory2_Swim', 'SubCategory2_Trend', 'Location_Chennai',\n",
      "       'Location_Gurgaon', 'Location_Mumbai', 'Channel_Web', 'age_bins_35-44',\n",
      "       'age_bins_45-54', 'age_bins_55-64', 'age_bins_above 65',\n",
      "       'age_bins_upto 24', 'review_len', 'noun_strength', 'polarity',\n",
      "       'subjectivity_score', 'compound_VADER_score', 'unique_word_fraction',\n",
      "       'is_gibberish', 'Product ID', 'Rating', 'Recommend Flag', '_x000d_',\n",
      "       'beautiful', 'big', 'bit', 'buy', 'color', 'comfortable', 'cute',\n",
      "       'dress', 'fabric', 'feel', 'fit', 'flatter', 'good', 'great', 'jean',\n",
      "       'large', 'length', 'like', 'little', 'long', 'look', 'love', 'make',\n",
      "       'material', 'medium', 'nice', 'order', 'pant', 'perfect', 'petite',\n",
      "       'pretty', 'purchase', 'quality', 'really', 'retailer', 'run', 'shirt',\n",
      "       'short', 'size', 'skirt', 'small', 'soft', 'sweater', 'think', 'try',\n",
      "       'waist', 'want', 'wear', 'work'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "reviewsFE_final_df = pd.concat([reviewsFE_final_df, words_df], axis=1)\n",
    "\n",
    "# Reset index and show the final DataFrame\n",
    "reviewsFE_final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(reviewsFE_final_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6712195-9a51-4d3d-8d57-0ad757cd0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = reviewsFE_final_df.drop(columns=to_drop)\n",
    "y = reviewsFE_final_df['Rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e600a0-86ff-4707-b0bf-393a54ada20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy\n",
      " 0.6052084997603451\n",
      "Test Accuracy\n",
      " 0.5891373801916933\n",
      "CLASSIFICATION REPORT: Logistic Regression\n",
      "Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.20      0.27       666\n",
      "           2       0.33      0.11      0.16      1242\n",
      "           3       0.37      0.27      0.31      2266\n",
      "           4       0.42      0.19      0.26      4062\n",
      "           5       0.67      0.92      0.77     10541\n",
      "\n",
      "    accuracy                           0.61     18777\n",
      "   macro avg       0.44      0.34      0.36     18777\n",
      "weighted avg       0.55      0.61      0.55     18777\n",
      "\n",
      "Test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.19      0.26       176\n",
      "           2       0.38      0.14      0.20       323\n",
      "           3       0.31      0.20      0.24       605\n",
      "           4       0.38      0.17      0.23      1015\n",
      "           5       0.66      0.93      0.77      2576\n",
      "\n",
      "    accuracy                           0.59      4695\n",
      "   macro avg       0.42      0.33      0.34      4695\n",
      "weighted avg       0.52      0.59      0.53      4695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "lr_classifier = LogisticRegression(max_iter=5000)\n",
    "lr_classifier.fit(X_train,y_train)\n",
    "print(\"Training Accuracy\\n\", accuracy_score(y_train,lr_classifier.predict(X_train)))\n",
    "print(\"Test Accuracy\\n\", accuracy_score(y_test,lr_classifier.predict(X_test)))\n",
    "\n",
    "print('CLASSIFICATION REPORT: Logistic Regression')\n",
    "print(\"Training\\n\", classification_report(y_train,lr_classifier.predict(X_train)))\n",
    "print(\"Test \\n\", classification_report(y_test,lr_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b13a9e-36ea-4884-8679-214eacfc9e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy\n",
      " 0.9937689726793417\n",
      "Test Accuracy\n",
      " 0.4696485623003195\n",
      "CLASSIFICATION REPORT: Decision Tree Classifier\n",
      "Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      0.99       666\n",
      "           2       1.00      1.00      1.00      1242\n",
      "           3       0.99      0.99      0.99      2266\n",
      "           4       0.99      0.99      0.99      4062\n",
      "           5       0.99      1.00      1.00     10541\n",
      "\n",
      "    accuracy                           0.99     18777\n",
      "   macro avg       0.99      0.99      0.99     18777\n",
      "weighted avg       0.99      0.99      0.99     18777\n",
      "\n",
      "Test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.18      0.15      0.16       176\n",
      "           2       0.15      0.14      0.14       323\n",
      "           3       0.24      0.25      0.25       605\n",
      "           4       0.25      0.25      0.25      1015\n",
      "           5       0.66      0.67      0.66      2576\n",
      "\n",
      "    accuracy                           0.47      4695\n",
      "   macro avg       0.30      0.29      0.29      4695\n",
      "weighted avg       0.46      0.47      0.47      4695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train,y_train)\n",
    "\n",
    "print(\"Training Accuracy\\n\", accuracy_score(y_train,dt_classifier.predict(X_train)))\n",
    "print(\"Test Accuracy\\n\", accuracy_score(y_test,dt_classifier.predict(X_test)))\n",
    "\n",
    "print('CLASSIFICATION REPORT: Decision Tree Classifier')\n",
    "print(\"Training\\n\", classification_report(y_train,dt_classifier.predict(X_train)))\n",
    "print(\"Test \\n\", classification_report(y_test,dt_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25f5701c-fb5b-4172-b0cc-d9c98eb714a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy\n",
      " 0.9937157160355754\n",
      "Test Accuracy\n",
      " 0.5716719914802982\n",
      "CLASSIFICATION REPORT: Random Forest Classifier\n",
      "Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.99      0.99       666\n",
      "           2       1.00      0.99      1.00      1242\n",
      "           3       1.00      0.99      0.99      2266\n",
      "           4       0.99      0.99      0.99      4062\n",
      "           5       0.99      1.00      0.99     10541\n",
      "\n",
      "    accuracy                           0.99     18777\n",
      "   macro avg       1.00      0.99      0.99     18777\n",
      "weighted avg       0.99      0.99      0.99     18777\n",
      "\n",
      "Test \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.14      0.21       176\n",
      "           2       0.32      0.11      0.17       323\n",
      "           3       0.32      0.16      0.21       605\n",
      "           4       0.28      0.12      0.16      1015\n",
      "           5       0.63      0.94      0.76      2576\n",
      "\n",
      "    accuracy                           0.57      4695\n",
      "   macro avg       0.40      0.29      0.30      4695\n",
      "weighted avg       0.49      0.57      0.50      4695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_classifier = RandomForestClassifier(n_estimators=50, n_jobs = -1, oob_score = True,random_state=42)\n",
    "rfc_classifier.fit(X_train,y_train)\n",
    "\n",
    "print(\"Training Accuracy\\n\", accuracy_score(y_train,rfc_classifier.predict(X_train)))\n",
    "print(\"Test Accuracy\\n\", accuracy_score(y_test,rfc_classifier.predict(X_test)))\n",
    "\n",
    "print('CLASSIFICATION REPORT: Random Forest Classifier')\n",
    "print(\"Training\\n\", classification_report(y_train,rfc_classifier.predict(X_train)))\n",
    "print(\"Test \\n\", classification_report(y_test,rfc_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8d902-5a14-4c0b-9f66-035433720224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
